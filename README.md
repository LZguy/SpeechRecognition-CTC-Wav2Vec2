# SpeechRecognition-CTC-Wav2Vec2

This project was completed as part of the **Deep Learning for Speech Signals** course (Technion, Spring 2025).  
It includes two main tasks: implementing the CTC forward probability algorithm and building an ASR system with Wav2Vec2 and a KenLM language model.

---

## ğŸ“‘ Project Overview
1. **CTC Forward Algorithm**  
   - Implemented in `ex_5_part1.py`.  
   - Computes the probability of a transcription sequence given a matrix of per-frame symbol probabilities `y[t,k]`.  
   - Tested with the provided `mat1.npy` file and sample transcriptions.

2. **Automatic Speech Recognition with Wav2Vec2 + KenLM**  
   - Implemented in `ex_5_part2.py`.  
   - Uses HuggingFaceâ€™s Wav2Vec2 pretrained acoustic model.  
   - Decodes outputs with a beam search decoder enhanced by a **KenLM n-gram language model** (`kenlm.arpa`).  
   - Input: train/test audio files with transcripts.  
   - Output: predicted text sequences, aligned with digits and letters.

---

## ğŸ“‚ Project Structure
```
DLSpeech_Ex5/
â”œâ”€ docs/
â”‚ â”œâ”€ DLSpeech_Ex5_046747.pdf # Original assignment instructions
â”‚ â”œâ”€ DLSpeech_Ex5_046747_updated.pdf # Updated instructions
â”‚ â”œâ”€ ex_5.pdf # Submitted report
â”œâ”€ data/ #most data is missing, will be delivered in the future
â”‚ â”œâ”€ train_transcription.txt # Training transcriptions
â”‚ â”œâ”€ lexicon.txt # Lexicon mapping for beam search
â”‚ â”œâ”€ mat1.npy # Probability matrix (used in Part 1)
â”‚ â”œâ”€ test/ # Test audio files (not included in repo)
â”‚ â””â”€ train/ # Training audio files (not included in repo)
â”œâ”€ src/
â”‚ â”œâ”€ ex_5_part1.py # CTC forward algorithm
â”‚ â”œâ”€ ex_5_part2.py # Wav2Vec2 + KenLM ASR pipeline
â”‚ â””â”€ kenlm.arpa # KenLM language model (large file)
â”œâ”€ results/
â”‚ â””â”€ output.txt # Example output predictions
â”œâ”€ .gitignore
â”œâ”€ LICENSE
â””â”€ README.md
```

---

## ğŸ“Š Data

Due to size, the full datasets are not stored directly in this repository.  
They can be downloaded from Google Drive:

- [train.zip](https://drive.google.com/uc?id=1jNmYJoXHlCOTD5j5aXa9DpA7DTEflHbo)  
- [test.zip](https://drive.google.com/uc?id=1-nkIkgEyUWgIpYeoGAY-Ml2LoTnknTIN)  

Unzip them into the `data/` directory before running the code:
```
unzip train.zip -d data/train
unzip test.zip -d data/test
```
Other resources stored in this repo:
- `train_transcription.txt` â€“ contains the training transcriptions.  
- `lexicon.txt` â€“ defines the lexicon for beam search decoding.  
- `mat1.npy` â€“ NumPy array of probabilities for Part 1 (CTC).

---

## ğŸ“œ Results
- `output.txt` â€“ Example system output, mapping spoken digits/letters into text.  
- Evaluation included WER (Word Error Rate) and CER (Character Error Rate) using the **jiwer** library.  

---

## âš™ï¸ Requirements
- Python 3.9+  
- PyTorch + Torchaudio  
- HuggingFace `transformers`  
- `kenlm`  
- `flashlight-text`  
- `numpy`, `pandas`, `tqdm`, `jiwer`  

Install dependencies:
```bash
pip install torch torchaudio transformers numpy pandas tqdm jiwer
pip install https://github.com/kpu/kenlm/archive/master.zip
pip install flashlight-text

## â–¶ï¸ How to Run

### Part 1 â€“ CTC Forward Probability

```bash
python src/ex_5_part1.py data/mat1.npy "aaabb" "abc"
```

Outputs the forward probability of the sequence.

---

### Part 2 â€“ ASR with Wav2Vec2 + KenLM

1. Train / fine-tune Wav2Vec2 on the `train/` data.  

2. Run decoding with beam search and KenLM:
   ```bash
   python src/ex_5_part2.py --data data/test --lexicon data/lexicon.txt --lm src/kenlm.arpa
   ```

3. Results are written to `results/output.txt`.
